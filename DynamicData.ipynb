{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DynamicData.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/misbahsy/APMonitor-do/blob/master/DynamicData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ctTMijOl7uUU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Dynamic Data Introduction\n",
        "\n",
        "Data manipulation is important for dynamic optimization in order to set up simulations that utilize time-varying information. Several aspects of dynamic optimization involve the import, validation, filtering, manipulation, and display of large data sets. Select one of the following tutorials below on using MATLAB or Python to import, manipulate, and export data sets."
      ]
    },
    {
      "metadata": {
        "id": "C6SH6jmt7otM",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "54c2f260-d7cc-4a72-afd3-5b9b83831cae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        }
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "%%html\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/E56egH10RJA\" frameborder=\"0\" allowfullscreen></iframe>\n",
        "\n",
        "<div class='vspace'></div>\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Tq6rCWPdXoQ\" frameborder=\"0\" allowfullscreen></iframe>\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/E56egH10RJA\" frameborder=\"0\" allowfullscreen></iframe>\n",
              "\n",
              "<div class='vspace'></div>\n",
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Tq6rCWPdXoQ\" frameborder=\"0\" allowfullscreen></iframe>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "WRBmTQN48fZ6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Real Data Challenges\n",
        "Real-data sources have a number of issues that can make simulation challenging. Measurements are used as inputs to a model, for parameter estimation, or in empirical model regression. Bad measurements can greatly affect the resulting model predictions, especially if strategies are not employed to minimize the effect of bad data.\n",
        "\n",
        "A first step in data validation is gross error detection or when the data is clearly bad based on statistics or heuristics. Methods to automatically detect bad data include upper and lower validity limits and change validity limits. An example of a lower validity limit may be a requirement for positive (>0) values from a flow meter. Also, flow meters may not be able to detect flows above a certain limit, leading to an upper limit as well. An example of a change validity limit may be to detect sudden jumps in a measurement that are not realistic. For example, a gas chromatograph may suddenly report a jump in a gas concentration. If the gas chromatograph is measuring the concentration of a large gas phase polyethylene reactor, it is unrealistic for that concentration to change more than a certain rate. A change validity limit is able to catch these sudden shifts with gross error detection.\n"
      ]
    },
    {
      "metadata": {
        "id": "IufntCKNKjk3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "</p>\n",
        "<div class='vspace'></div><div><img src='http://apmonitor.com/do/uploads/Main/bad_data.png' alt='' title='' /></div>\n",
        "<p class='vspace'><strong>Figure 1.</strong> Example of (1) outlier, (2) drift, and (3) noise<sup><a class='urllink' href='https://dx.doi.org/10.1016/j.compchemeng.2014.04.013' rel='nofollow'>1</a></sup>.\n",
        "</p>"
      ]
    },
    {
      "metadata": {
        "id": "-RihCyPN89MM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Other examples of real-data issues include outliers (infrequent data points that are temporarily outside of an otherwise consistent trend in the data), noise (random variations in the data due to resolution or variations in the measurement or transmission of the data), and drift (inaccurate and gradual increase or decrease of the measurement value that does not represent the true values). Data may also be infrequent (such as measurements that occur every few hours or not at regular intervals), intermittent (such as from unreliable measurements that report good values for only certain periods of time), or time delayed (measurements that are reported after a waiting period). Synchronization of real data to process models can be challenging for all of these reasons.\n",
        "\n",
        "Some estimators and controllers are designed with ideal measurements in simulation but then fail to perform in practice due to the issues with real measurements. It is important to use methods that perform well in a variety of situations and can either reject or minimize the effect of bad data."
      ]
    },
    {
      "metadata": {
        "id": "cHQlyZ7LKri3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Exercise\n",
        "<p><strong>Objective:</strong> Understand the effect of bad data on dynamic optimization algorithms including estimator and control performance. Create a MATLAB or Python script to simulate and display the results. <em>Estimated Time: 2 hours</em>\n",
        "</p>\n",
        "<p class='vspace'>The flowrate of mud and cuttings is especially important with managed pressure drilling (MPD) in order to detect gas influx or fluid losses. There are a range of measurement instruments for flow such as a <a class='urllink' href='https://en.wikipedia.org/wiki/Mass_flow_meter' rel='nofollow'>mass flow meter or Coriolis  flow meter (most accurate)</a> and a <a class='urllink' href='https://en.wikipedia.org/wiki/Flow_measurement#Paddle_wheel_meter' rel='nofollow'>paddle wheel (least accurate)</a>. This particular system has dynamics that are described by the following equation with C<sub>v</sub>=1, <em>u</em> is the valve opening, and <em>d</em> is a disturbance.\n",
        "</p>\n",
        "<div class='vspace'></div><pre> 0.1 d<em>F<sub>1</sub></em>/dt = -<em>F<sub>1</sub></em> + C<sub>v</sub> <em>u</em> + <em>d</em>\n",
        "</pre><div class='vspace'></div><div><img src='http://apmonitor.com/do/uploads/Main/drilling_flowrate.png' alt='' title='' /></div>\n",
        "<p class='vspace'>Determine the effect of bad data (outliers, drift, and noise) on estimators such as such as moving horizon estimation. There is no need to design the estimators for this problem. The estimator scripts are below with sections that can be added to simulate the effect of bad data<sup>1</sup>. Only an outlier has been added to these code. The code should be modified to include other common phenomena such as measurement drift (gradual ramp away from the true value) and an increase in noise (random fluctuations). Comment on the effect of corrupted data on real-time estimation and why some methods are more effective at rejecting bad data.\n",
        "</p>\n",
        "<div class='vspace'></div><div><img src='http://apmonitor.com/do/uploads/Main/download.png' alt='' title='' /> <a class='urllink' href='http://apmonitor.com/do/uploads/Main/bad_data_exercise.zip' rel='nofollow'>Estimation with Outliers in MATLAB and Python</a></div>\n",
        "\n",
        "##Solution\n",
        "<div><img src='http://apmonitor.com/do/uploads/Main/bad_data_estimation.png' alt='' title='' /></div>"
      ]
    },
    {
      "metadata": {
        "id": "jGGyBAuD9Tzv",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Solution with GEKKO\n",
        "\n",
        "try:\n",
        "    from pip import main as pipmain\n",
        "except:\n",
        "    from pip._internal import main as pipmain\n",
        "pipmain(['install','gekko'])\n",
        "\n",
        "from __future__ import division\n",
        "from gekko import GEKKO\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# intial parameters\n",
        "n_iter = 150 # number of cycles\n",
        "x = 37.727 # true value\n",
        "# filtered bias update\n",
        "alpha = 0.0951\n",
        "# mhe tuning\n",
        "horizon = 30\n",
        "\n",
        "#%% Model\n",
        "\n",
        "#Initialize model\n",
        "m = GEKKO(remote=False)\n",
        "\n",
        "# Solve options\n",
        "rmt = True # Remote: True or False\n",
        "# For rmt=True, specify server\n",
        "m.server = 'https://byu.apmonitor.com'\n",
        "\n",
        "#time array \n",
        "m.time = np.arange(50)\n",
        "\n",
        "#Parameters\n",
        "u = m.Param(value=42)\n",
        "d = m.FV(value=0)\n",
        "Cv = m.Param(value=1)\n",
        "tau = m.Param(value=0.1)\n",
        "\n",
        "#Variable\n",
        "flow = m.CV(value=42)\n",
        "\n",
        "#Equation \n",
        "m.Equation(tau * flow.dt() == -flow + Cv * u + d)\n",
        "\n",
        "# Options\n",
        "m.options.imode = 5\n",
        "m.options.ev_type = 1 #start with l1 norm\n",
        "m.options.coldstart = 1\n",
        "m.options.solver = 1  # APOPT solver\n",
        "\n",
        "d.status = 1\n",
        "flow.fstatus = 1\n",
        "flow.wmeas = 100\n",
        "flow.wmodel = 0\n",
        "#flow.dcost = 0\n",
        "\n",
        "# Initialize L1 application\n",
        "m.solve()\n",
        "\n",
        "#%% Other Setup\n",
        "# Create storage for results\n",
        "xtrue = x * np.ones(n_iter+1)\n",
        "z = x * np.ones(n_iter+1)\n",
        "time = np.zeros(n_iter+1)\n",
        "xb = np.empty(n_iter+1)\n",
        "x1mhe = np.empty(n_iter+1)\n",
        "x2mhe = np.empty(n_iter+1)\n",
        "\n",
        "# initial estimator values\n",
        "x0 = 40\n",
        "xb[0] = x0\n",
        "x1mhe[0] = x0\n",
        "x2mhe[0] = x0\n",
        "\n",
        "# outliers\n",
        "for i in range(n_iter+1):\n",
        "    z[i] = x + (random.random()-0.5)*2.0\n",
        "z[50] = 100\n",
        "z[100] = 0\n",
        "\n",
        "#%% L1 Application\n",
        "\n",
        "## Cycle through measurement sequentially\n",
        "for k in range(1, n_iter+1):\n",
        "    print( 'Cycle ' + str(k) + ' of ' + str(n_iter))\n",
        "    time[k] = k\n",
        "\n",
        "    # L1-norm MHE\n",
        "    flow.meas = z[k] \n",
        "    m.solve()\n",
        "    x1mhe[k] = flow.model\n",
        "\n",
        "print(\"Finished L1\")\n",
        "#%% L2 application\n",
        "\n",
        "#clear L1//\n",
        "m.clear_data()\n",
        "# Options for L2\n",
        "m.options.ev_type = 2 #start with l1 norm\n",
        "m.options.coldstart = 1 #reinitialize\n",
        "\n",
        "flow.wmodel = 10\n",
        "\n",
        "# Initialize L2 application\n",
        "m.solve()\n",
        "\n",
        "## Cycle through measurement sequentially\n",
        "for k in range(1, n_iter+1):\n",
        "    print ('Cycle ' + str(k) + ' of ' + str(n_iter))\n",
        "    time[k] = k\n",
        "\n",
        "    # L2-norm MHE\n",
        "    flow.meas = z[k] \n",
        "    m.solve()\n",
        "    x2mhe[k] = flow.model\n",
        "\n",
        "#%% Filtered bias update\n",
        "\n",
        "## Cycle through measurement sequentially\n",
        "for k in range(1, n_iter+1):\n",
        "    print ('Cycle ' + str(k) + ' of ' + str(n_iter))\n",
        "    time[k] = k\n",
        "\n",
        "    # filtered bias update\n",
        "    xb[k] = alpha * z[k] + (1.0-alpha) * xb[k-1] \n",
        "\n",
        "\n",
        "#%% plot results\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(1)\n",
        "plt.plot(time,z,'kx',linewidth=2)\n",
        "plt.plot(time,xb,'g--',linewidth=3)\n",
        "plt.plot(time,x2mhe,'k-',linewidth=3)\n",
        "plt.plot(time,x1mhe,'r.-',linewidth=3)\n",
        "plt.plot(time,xtrue,'k:',linewidth=2)\n",
        "plt.legend(['Measurement','Filtered Bias Update','Sq Error MHE','l_1-Norm MHE','Actual Value'])\n",
        "plt.xlabel('Time (sec)')\n",
        "plt.ylabel('Flow Rate (T/hr)')\n",
        "plt.axis([0, time[n_iter], 32, 45])\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}