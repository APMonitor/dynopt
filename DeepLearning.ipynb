{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/misbahsy/APMonitor-do/blob/master/DeepLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "2vGEdP1nIWYa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Deep Learning\n",
        "\n",
        "<p class='vspace'>Deep learning is a type of machine learning with a multi-layered neural network. It is one of many machine learning methods for synthesizing data into a predictive form.\n",
        "</p>\n",
        "<div class='vspace'></div><div><img width='350px' src='http://apmonitor.com/do/uploads/Main/ai_overview.png' alt='' title='' /></div>\n",
        "<p class='vspace'>Two applications of deep learning are regression (predict outcome) and classification (distinguish among discrete options). In each case, there is training data that is used to adjust weights (unknown parameters) that minimize a loss function (objective function).\n",
        "</p>\n",
        "<div class='vspace'></div>\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ti_kFGDdIdGQ",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "c168b1b9-b025-4f48-f910-2487d4700e5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "%%html\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/zOCVTPb5DiM\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/zOCVTPb5DiM\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "7E_mKz5YMUF0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<p class='vspace'>A trained model predicts outcomes based on new input conditions that aren't in the original data set. Some of the typical steps for building and deploying a deep learning application are data consolidation, data cleansing, model building, training, validation, and deployment. Example Python code is provided for each of the steps.\n",
        "</p>\n",
        "<div class='vspace'></div>\n",
        "\n",
        "##Data Preparation\n",
        "<ul><li>Consolidation - consolidation is the process of combining disparate data (Excel spreadsheet, PDF report, database, cloud storage) into a single repository.\n",
        "</li><li>Data Cleansing - bad data should be removed and may include outliers, missing entries, failed sensors, or other types of missing or corrupted information.\n",
        "</li><li>Inputs and Outputs - data is separated into inputs (explanatory variables) and outputs (supervisory signal). The inputs will be fed into a series of functions to produce an output prediction. The squared difference between the predicted output and the measured output is a typical loss (objective) function for fitting.  \n",
        "</li><li>Scaling - scaling all data (inputs and outputs) to a range of 0-1 can improve the training process.\n",
        "</li><li>Training and Validation - data is divided into training (e.g. 80%) and validation (e.g. 20%) sets so that the model fit can be evaluated independently of the training. Cross-validation is an approach to divide the training data into multiple sets that are fit separately. The parameter consistency is compared between the multiple models.\n",
        "</li></ul><div class='vspace'></div>\n",
        "<video controls autoplay loop>\n",
        "  <source src=\"/do/uploads/Main/keras_tutorial.mp4\" type=\"video/mp4\">\n",
        "  Your browser does not support the video tag.\n",
        "</video> \n"
      ]
    },
    {
      "metadata": {
        "id": "vFCizH87I6PM",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "0a8d744b-41a4-4599-b080-49e8633d9ba3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        }
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "%%html\n",
        "\n",
        "<video controls autoplay loop>\n",
        "  <source src=\"http://apmonitor.com/do/uploads/Main/keras_tutorial.mp4\" type=\"video/mp4\">\n",
        "  Your browser does not support the video tag.\n",
        "</video> \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<video controls autoplay loop>\n",
              "  <source src=\"http://apmonitor.com/do/uploads/Main/keras_tutorial.mp4\" type=\"video/mp4\">\n",
              "  Your browser does not support the video tag.\n",
              "</video> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "NbMMmh1nNc0V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###1. Data Export with Numpy / Import with Pandas"
      ]
    },
    {
      "metadata": {
        "id": "9XOC8VEeJWUl",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "import matplotlib.pyplot as plt  \n",
        "\n",
        "# generate training data\n",
        "x = np.linspace(0.0,2*np.pi,20)\n",
        "y = np.sin(x)\n",
        "# save training data to file\n",
        "data = np.vstack((x,y)).T\n",
        "np.savetxt('train_data.csv',data,header='x,y',comments='',delimiter=',')\n",
        "\n",
        "# generate test data\n",
        "x = np.linspace(0.0,2*np.pi,100)\n",
        "y = np.sin(x)\n",
        "# save test data to file\n",
        "data = np.vstack((x,y)).T\n",
        "np.savetxt('test_data.csv',data,header='x,y',comments='',delimiter=',')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vqQSBs8NNh1F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###2. Data Scaling with scikit-learn"
      ]
    },
    {
      "metadata": {
        "id": "GgLVIiWmJ24z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load training and test data with pandas\n",
        "train_df = pd.read_csv('train_data.csv')\n",
        "test_df = pd.read_csv('test_data.csv')\n",
        "\n",
        "# scale values to 0 to 1 for the ANN to work well\n",
        "s = MinMaxScaler(feature_range=(0,1))\n",
        "\n",
        "# scale training and test data\n",
        "sc_train = s.fit_transform(train_df)\n",
        "sc_test = s.transform(test_df)\n",
        "\n",
        "# print scaling adjustments\n",
        "print('Scalar multipliers')\n",
        "print(s.scale_)\n",
        "print('Scalar minimum')\n",
        "print(s.min_)\n",
        "\n",
        "# convert scaled values back to dataframe\n",
        "sc_train_df = pd.DataFrame(sc_train, columns=train_df.columns.values)\n",
        "sc_test_df = pd.DataFrame(sc_test, columns=test_df.columns.values)\n",
        "\n",
        "# save scaled values to CSV files\n",
        "sc_train_df.to_csv('train_scaled.csv', index=False)\n",
        "sc_test_df.to_csv('test_scaled.csv', index=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "637a3PkLNFBV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Model Build\n",
        "\n",
        "\n",
        "<p>An artificial neural network relates inputs to outputs with layers of nodes. There nodes are also called neurons because they emulate the learning process that occurs in the brain where the connection strength is adjusted to change the learned outcome.\n",
        "</p>\n",
        "<div class='vspace'></div><div><img width='300px' src='http://apmonitor.com/do/uploads/Main/neural_network.png' alt='' title='' /></div>\n",
        "<p class='vspace'>Instead of just one layer, deep learning uses a multi-layered neural network. This neural network may have linear or nonlinear layers. The layer form is determined by the type of activation function (e.g. linear, rectified linear unit (ReLU), hyperbolic tangent) that transforms each intermediate input to the next layer.\n",
        "</p>\n",
        "<div class='vspace'></div><div><img width='550px' src='http://apmonitor.com/do/uploads/Main/deep_neural_network.png' alt='' title='' /></div>\n",
        "<p class='vspace'>Linear layers at the beginning and end are common. Increasing the number of layers can improve the fit but also requires more computational power for training and may cause the model to be over-parameterized and decrease the predictive capability.\n",
        "</p>"
      ]
    },
    {
      "metadata": {
        "id": "K6sPoZYlNO9p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Training\n",
        "\n",
        "\n",
        "<p>A loss function (objective function) is minimized by adjusting the weights (unknown parameters) of the multi-layered neural network. An epoch is a full training cycle and is one iteration of the learning algorithm. A decrease in the loss function is monitored to ensure that the number of epochs is sufficient to refine the predictions without over-fitting to data irregularities such as random fluctuations.\n",
        "</p>"
      ]
    },
    {
      "metadata": {
        "id": "fsiZ8Q42NrxG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###3. Model Build and Train with Keras\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "4esWzacmK5b5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim=1, activation='linear'))\n",
        "model.add(Dense(2, activation='linear'))\n",
        "model.add(Dense(2, activation='tanh'))\n",
        "model.add(Dense(2, activation='linear'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
        "\n",
        "# load training data\n",
        "train_df = pd.read_csv(\"train_scaled.csv\")\n",
        "X1 = train_df.drop('y', axis=1).values\n",
        "Y1 = train_df[['y']].values\n",
        "\n",
        "# train the model\n",
        "model.fit(X1,Y1,epochs=5000,verbose=0,shuffle=True)\n",
        "\n",
        "# Save the model to hard drive\n",
        "#model.save('model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GwGS4LyRNZ5-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Validation\n",
        "\n",
        "<p>The validation test set assesses the ability of the neural network to predict based on new conditions that were not part of the training set. Parity plots are one of many graphical methods to assess the fit. Mean squared error (MSE) or the R<sup>2</sup> value are common quantitative measures of the fit.\n",
        "</p>"
      ]
    },
    {
      "metadata": {
        "id": "TRL-fjniNvaG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###4. Model Validation with Keras\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "-0mc1QOGLmu2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the model from hard drive\n",
        "#model.load('model.h5')\n",
        "\n",
        "# load test data\n",
        "test_df = pd.read_csv(\"test_scaled.csv\")\n",
        "X2 = test_df.drop('y', axis=1).values\n",
        "Y2 = test_df[['y']].values\n",
        "\n",
        "# test the model\n",
        "mse = model.evaluate(X2,Y2, verbose=1)\n",
        "\n",
        "print('Mean Squared Error: ', mse)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MBN6X64TNiIl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Deployment\n",
        "\n",
        "<p>The deep learning algorithm may be deployed across a wide variety of computing infrastructure or cloud-based services. There is specialized hardware such as <a class='urllink' href='https://en.wikipedia.org/wiki/Tensor_processing_unit' rel='nofollow'>Tensor processing units</a> that is designed for high volume or low power. Python packages such as <a class='urllink' href='https://en.wikipedia.org/wiki/Keras' rel='nofollow'>Keras</a> are designed for prototyping and run on top of more capable and configurable packages such as <a class='urllink' href='https://en.wikipedia.org/wiki/TensorFlow' rel='nofollow'>TensorFlow</a>.\n",
        "</p>\n",
        "<p class='vspace'>Self-learning algorithms continue to refine the model based on new data. This is similar to the <a class='wikilink' href='http://apmonitor.com/do/index.php/Main/MovingHorizonEstimation'>Moving Horizon Estimation</a> approach where unknown parameters are updated to best match the new measurement while also preserving the prior training. \n",
        "</p>"
      ]
    },
    {
      "metadata": {
        "id": "HxQVU3J5OV8Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###5. Model Predictions with Keras\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "M0D_uftQMEzy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# generate prediction data\n",
        "x = np.linspace(-2*np.pi,4*np.pi,100)\n",
        "y = np.sin(x)\n",
        "# scale input\n",
        "X3 = x*s.scale_[0]+s.min_[0]\n",
        "# predict\n",
        "Y3P = model.predict(X3)\n",
        "# unscale output\n",
        "yp = (Y3P-s.min_[1])/s.scale_[1]\n",
        "\n",
        "plt.figure()\n",
        "plt.plot((X1-s.min_[0])/s.scale_[0], \\\n",
        "                 (Y1-s.min_[1])/s.scale_[1], \\\n",
        "                 'bo',label='train')\n",
        "plt.plot(x,y,'r-',label='actual')\n",
        "plt.plot(x,yp,'k--',label='predict')\n",
        "plt.legend(loc='best')\n",
        "plt.savefig('results.png')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y3f9xokeNuGd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Exercise\n",
        "<p>Repeat the above exercise that was shown with Keras with Python Gekko. Change the activation function to a cosine to better extrapolate outside of the training region. The training data are 20 equally spaced points for <em>x</em> between <em>0</em> and `2\\pi` with outputs generated from the sine function `y = \\sin(x)`.\n",
        "</p>\n",
        "<div class='vspace'></div>"
      ]
    },
    {
      "metadata": {
        "id": "PhXh73NPMMpL",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "be15c53d-381c-45f8-e602-2e1486b6d88e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "%%html\n",
        "\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/kOmhU2XxLCY\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/kOmhU2XxLCY\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "kVMNn4P7M1Iw",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title GEKKO Solution\n",
        "\n",
        "try:\n",
        "    from pip import main as pipmain\n",
        "except:\n",
        "    from pip._internal import main as pipmain\n",
        "pipmain(['install','gekko'])\n",
        "\n",
        "from gekko import GEKKO\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt  \n",
        "\n",
        "# generate training data\n",
        "x = np.linspace(0.0,2*np.pi,20)\n",
        "y = np.sin(x)\n",
        "\n",
        "# option for fitting function\n",
        "select = True # True / False\n",
        "if select:\n",
        "    # Size with cosine function\n",
        "    nin = 1  # inputs\n",
        "    n1 = 1   # hidden layer 1 (linear)\n",
        "    n2 = 1   # hidden layer 2 (nonlinear)\n",
        "    n3 = 1   # hidden layer 3 (linear)\n",
        "    nout = 1 # outputs\n",
        "else:\n",
        "    # Size with hyperbolic tangent function\n",
        "    nin = 1  # inputs\n",
        "    n1 = 2   # hidden layer 1 (linear)\n",
        "    n2 = 2   # hidden layer 2 (nonlinear)\n",
        "    n3 = 2   # hidden layer 3 (linear)\n",
        "    nout = 1 # outputs\n",
        "\n",
        "# Initialize gekko\n",
        "train = GEKKO() \n",
        "test = GEKKO()\n",
        "\n",
        "model = [train,test]\n",
        "\n",
        "for m in model:\n",
        "    # input(s)\n",
        "    m.inpt = m.Param()\n",
        "\n",
        "    # layer 1\n",
        "    m.w1 = m.Array(m.FV, (nin,n1))\n",
        "    m.l1 = [m.Intermediate(m.w1[0,i]*m.inpt) for i in range(n1)]\n",
        "\n",
        "    # layer 2\n",
        "    m.w2a = m.Array(m.FV, (n1,n2))\n",
        "    m.w2b = m.Array(m.FV, (n1,n2))\n",
        "    if select:\n",
        "        m.l2 = [m.Intermediate(sum([m.cos(m.w2a[j,i]+m.w2b[j,i]*m.l1[j]) \\\n",
        "                                for j in range(n1)])) for i in range(n2)]\n",
        "    else:\n",
        "        m.l2 = [m.Intermediate(sum([m.tanh(m.w2a[j,i]+m.w2b[j,i]*m.l1[j]) \\\n",
        "                                for j in range(n1)])) for i in range(n2)]\n",
        "\n",
        "    # layer 3\n",
        "    m.w3 = m.Array(m.FV, (n2,n3))\n",
        "    m.l3 = [m.Intermediate(sum([m.w3[j,i]*m.l2[j] \\\n",
        "            for j in range(n2)])) for i in range(n3)]\n",
        "\n",
        "    # output(s)\n",
        "    m.outpt = m.CV()\n",
        "    m.Equation(m.outpt==sum([m.l3[i] for i in range(n3)]))\n",
        "\n",
        "    # flatten matrices\n",
        "    m.w1 = m.w1.flatten()\n",
        "    m.w2a = m.w2a.flatten()\n",
        "    m.w2b = m.w2b.flatten()\n",
        "    m.w3 = m.w3.flatten()\n",
        "\n",
        "# Fit parameter weights\n",
        "m = train\n",
        "m.inpt.value=x\n",
        "m.outpt.value=y\n",
        "m.outpt.FSTATUS = 1\n",
        "for i in range(len(m.w1)):\n",
        "    m.w1[i].FSTATUS=1\n",
        "    m.w1[i].STATUS=1\n",
        "    m.w1[i].MEAS=1.0\n",
        "for i in range(len(m.w2a)):\n",
        "    m.w2a[i].STATUS=1\n",
        "    m.w2b[i].STATUS=1\n",
        "    m.w2a[i].FSTATUS=1\n",
        "    m.w2b[i].FSTATUS=1\n",
        "    m.w2a[i].MEAS=1.0\n",
        "    m.w2b[i].MEAS=0.5\n",
        "for i in range(len(m.w3)):\n",
        "    m.w3[i].FSTATUS=1\n",
        "    m.w3[i].STATUS=1\n",
        "    m.w3[i].MEAS=1.0\n",
        "m.options.IMODE = 2\n",
        "m.options.SOLVER = 3\n",
        "m.options.EV_TYPE = 2\n",
        "m.solve(disp=False)\n",
        "\n",
        "# Test sample points\n",
        "m = test\n",
        "for i in range(len(m.w1)):\n",
        "    m.w1[i].MEAS=train.w1[i].NEWVAL\n",
        "    m.w1[i].FSTATUS = 1\n",
        "    print('w1['+str(i)+']: '+str(m.w1[i].MEAS))\n",
        "for i in range(len(m.w2a)):\n",
        "    m.w2a[i].MEAS=train.w2a[i].NEWVAL\n",
        "    m.w2b[i].MEAS=train.w2b[i].NEWVAL\n",
        "    m.w2a[i].FSTATUS = 1\n",
        "    m.w2b[i].FSTATUS = 1\n",
        "    print('w2a['+str(i)+']: '+str(m.w2a[i].MEAS))\n",
        "    print('w2b['+str(i)+']: '+str(m.w2b[i].MEAS))\n",
        "for i in range(len(m.w3)):\n",
        "    m.w3[i].MEAS=train.w3[i].NEWVAL\n",
        "    m.w3[i].FSTATUS = 1\n",
        "    print('w3['+str(i)+']: '+str(m.w3[i].MEAS))\n",
        "m.inpt.value=np.linspace(-2*np.pi,4*np.pi,100)\n",
        "m.options.IMODE = 2\n",
        "m.options.SOLVER = 3\n",
        "m.solve(disp=False)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(x,y,'bo',label='data')\n",
        "plt.plot(test.inpt.value,test.outpt.value,'r-',label='predict')\n",
        "plt.legend(loc='best')\n",
        "plt.ylabel('y')\n",
        "plt.xlabel('x')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}